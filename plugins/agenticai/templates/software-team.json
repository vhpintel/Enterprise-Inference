{
  "nodes": [
    {
      "id": "startAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 100.79370050359839,
        "y": 100
      },
      "data": {
        "id": "startAgentflow_0",
        "label": "Start",
        "version": 1.1,
        "name": "startAgentflow",
        "type": "Start",
        "color": "#7EE787",
        "hideInput": true,
        "baseClasses": [
          "Start"
        ],
        "category": "Agent Flows",
        "description": "Starting point of the agentflow",
        "inputParams": [
          {
            "label": "Input Type",
            "name": "startInputType",
            "type": "options",
            "options": [
              {
                "label": "Chat Input",
                "name": "chatInput",
                "description": "Start the conversation with chat input"
              },
              {
                "label": "Form Input",
                "name": "formInput",
                "description": "Start the workflow with form inputs"
              }
            ],
            "default": "chatInput",
            "id": "startAgentflow_0-input-startInputType-options",
            "display": true
          },
          {
            "label": "Form Title",
            "name": "formTitle",
            "type": "string",
            "placeholder": "Please Fill Out The Form",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formTitle-string",
            "display": false
          },
          {
            "label": "Form Description",
            "name": "formDescription",
            "type": "string",
            "placeholder": "Complete all fields below to continue",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formDescription-string",
            "display": false
          },
          {
            "label": "Form Input Types",
            "name": "formInputTypes",
            "description": "Specify the type of form input",
            "type": "array",
            "show": {
              "startInputType": "formInput"
            },
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Options",
                    "name": "options"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Label",
                "name": "label",
                "type": "string",
                "placeholder": "Label for the input"
              },
              {
                "label": "Variable Name",
                "name": "name",
                "type": "string",
                "placeholder": "Variable name for the input (must be camel case)",
                "description": "Variable name must be camel case. For example: firstName, lastName, etc."
              },
              {
                "label": "Add Options",
                "name": "addOptions",
                "type": "array",
                "show": {
                  "formInputTypes[$index].type": "options"
                },
                "array": [
                  {
                    "label": "Option",
                    "name": "option",
                    "type": "string"
                  }
                ]
              }
            ],
            "id": "startAgentflow_0-input-formInputTypes-array",
            "display": false
          },
          {
            "label": "Ephemeral Memory",
            "name": "startEphemeralMemory",
            "type": "boolean",
            "description": "Start fresh for every execution without past chat history",
            "optional": true,
            "id": "startAgentflow_0-input-startEphemeralMemory-boolean",
            "display": true
          },
          {
            "label": "Flow State",
            "name": "startState",
            "description": "Runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string",
                "placeholder": "Foo"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "placeholder": "Bar",
                "optional": true
              }
            ],
            "id": "startAgentflow_0-input-startState-array",
            "display": true
          },
          {
            "label": "Persist State",
            "name": "startPersistState",
            "type": "boolean",
            "description": "Persist the state in the same session",
            "optional": true,
            "id": "startAgentflow_0-input-startPersistState-boolean",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "startInputType": "chatInput",
          "formTitle": "",
          "formDescription": "",
          "formInputTypes": "",
          "startEphemeralMemory": "",
          "startState": [
            {
              "key": "next",
              "value": ""
            },
            {
              "key": "instructions",
              "value": ""
            }
          ],
          "startPersistState": ""
        },
        "outputAnchors": [
          {
            "id": "startAgentflow_0-output-startAgentflow",
            "label": "Start",
            "name": "startAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 103,
      "height": 66,
      "positionAbsolute": {
        "x": 100.79370050359839,
        "y": 100
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "llmAgentflow_0",
      "position": {
        "x": 272.17480201439355,
        "y": 45.45629949640161
      },
      "data": {
        "id": "llmAgentflow_0",
        "label": "Supervisor",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_0-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_0-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_0-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_0-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_0-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_0-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_0-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_0-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAICustom",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p><strong>You are a supervisor tasked with managing a conversation between the following workers:</strong></p><ul><li><p>Software Engineer</p></li><li><p>Code Reviewer</p></li></ul><p><strong>Given the following user request, respond with the worker to act next. </strong><br>Each worker will perform a task and respond with their results and status.<br>When finished, respond with <strong>FINISH</strong>.<br>Select strategically to minimize the number of steps taken.</p>"
            }
          ],
          "llmEnableMemory": true,
          "llmMemoryType": "allMessages",
          "llmUserMessage": "<p></p>",
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": [
            {
              "key": "next",
              "type": "enum",
              "enumValues": "SOFTWARE, REVIEWER, FINISH",
              "jsonSchema": "",
              "description": "The next worker to act"
            },
            {
              "key": "instructions",
              "type": "string",
              "enumValues": "",
              "jsonSchema": "",
              "description": "The specific instructions of the sub-tasks the next worker should accomplish."
            }
          ],
          "llmUpdateState": [
            {
              "key": "next",
              "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output.next\" data-label=\"output.next\">{{ output.next }}</span> </p>"
            },
            {
              "key": "instructions",
              "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output.instructions\" data-label=\"output.instructions\">{{ output.instructions }}</span> </p>"
            }
          ],
          "llmModelConfig": {
            "cache": "",
            "modelName": "your-model-id",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "your-model-endpoint",
            "baseOptions": "",
            "llmModel": "chatOpenAICustom"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_0-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 293,
      "height": 72,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 272.17480201439355,
        "y": 45.45629949640161
      }
    },
    {
      "id": "stickyNoteAgentflow_0",
      "position": {
        "x": 320.5771778416711,
        "y": -43.40187172705003
      },
      "data": {
        "id": "stickyNoteAgentflow_0",
        "label": "Sticky Note",
        "version": 1,
        "name": "stickyNoteAgentflow",
        "type": "StickyNote",
        "color": "#fee440",
        "baseClasses": [
          "StickyNote"
        ],
        "category": "Agent Flows",
        "description": "Add notes to the agent flow",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNoteAgentflow_0-input-note-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Decide whom to call next"
        },
        "outputAnchors": [
          {
            "id": "stickyNoteAgentflow_0-output-stickyNoteAgentflow",
            "label": "Sticky Note",
            "name": "stickyNoteAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "stickyNote",
      "width": 210,
      "height": 82,
      "selected": false,
      "positionAbsolute": {
        "x": 320.5771778416711,
        "y": -43.40187172705003
      },
      "dragging": false
    },
    {
      "id": "conditionAgentflow_0",
      "position": {
        "x": 632.6376351781316,
        "y": 44.06337565982208
      },
      "data": {
        "id": "conditionAgentflow_0",
        "label": "Condition 0",
        "version": 1,
        "name": "conditionAgentflow",
        "type": "Condition",
        "color": "#FFB938",
        "baseClasses": [
          "Condition"
        ],
        "category": "Agent Flows",
        "description": "Split flows based on If Else conditions",
        "inputParams": [
          {
            "label": "Conditions",
            "name": "conditions",
            "type": "array",
            "description": "Values to compare",
            "acceptVariable": true,
            "default": [
              {
                "type": "string",
                "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.next\" data-label=\"$flow.state.next\">{{ $flow.state.next }}</span> </p>",
                "operation": "equal",
                "value2": "<p>SOFTWARE</p>"
              }
            ],
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Value 1",
                "name": "value1",
                "type": "string",
                "default": "",
                "description": "First value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "string"
                }
              },
              {
                "label": "Operation",
                "name": "operation",
                "type": "options",
                "options": [
                  {
                    "label": "Contains",
                    "name": "contains"
                  },
                  {
                    "label": "Ends With",
                    "name": "endsWith"
                  },
                  {
                    "label": "Equal",
                    "name": "equal"
                  },
                  {
                    "label": "Not Contains",
                    "name": "notContains"
                  },
                  {
                    "label": "Not Equal",
                    "name": "notEqual"
                  },
                  {
                    "label": "Regex",
                    "name": "regex"
                  },
                  {
                    "label": "Starts With",
                    "name": "startsWith"
                  },
                  {
                    "label": "Is Empty",
                    "name": "isEmpty"
                  },
                  {
                    "label": "Not Empty",
                    "name": "notEmpty"
                  }
                ],
                "default": "equal",
                "description": "Type of operation",
                "show": {
                  "conditions[$index].type": "string"
                }
              },
              {
                "label": "Value 2",
                "name": "value2",
                "type": "string",
                "default": "",
                "description": "Second value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "string"
                },
                "hide": {
                  "conditions[$index].operation": [
                    "isEmpty",
                    "notEmpty"
                  ]
                }
              },
              {
                "label": "Value 1",
                "name": "value1",
                "type": "number",
                "default": "",
                "description": "First value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "number"
                }
              },
              {
                "label": "Operation",
                "name": "operation",
                "type": "options",
                "options": [
                  {
                    "label": "Smaller",
                    "name": "smaller"
                  },
                  {
                    "label": "Smaller Equal",
                    "name": "smallerEqual"
                  },
                  {
                    "label": "Equal",
                    "name": "equal"
                  },
                  {
                    "label": "Not Equal",
                    "name": "notEqual"
                  },
                  {
                    "label": "Larger",
                    "name": "larger"
                  },
                  {
                    "label": "Larger Equal",
                    "name": "largerEqual"
                  },
                  {
                    "label": "Is Empty",
                    "name": "isEmpty"
                  },
                  {
                    "label": "Not Empty",
                    "name": "notEmpty"
                  }
                ],
                "default": "equal",
                "description": "Type of operation",
                "show": {
                  "conditions[$index].type": "number"
                }
              },
              {
                "label": "Value 2",
                "name": "value2",
                "type": "number",
                "default": 0,
                "description": "Second value to be compared with",
                "acceptVariable": true,
                "show": {
                  "conditions[$index].type": "number"
                }
              },
              {
                "label": "Value 1",
                "name": "value1",
                "type": "boolean",
                "default": false,
                "description": "First value to be compared with",
                "show": {
                  "conditions[$index].type": "boolean"
                }
              },
              {
                "label": "Operation",
                "name": "operation",
                "type": "options",
                "options": [
                  {
                    "label": "Equal",
                    "name": "equal"
                  },
                  {
                    "label": "Not Equal",
                    "name": "notEqual"
                  }
                ],
                "default": "equal",
                "description": "Type of operation",
                "show": {
                  "conditions[$index].type": "boolean"
                }
              },
              {
                "label": "Value 2",
                "name": "value2",
                "type": "boolean",
                "default": false,
                "description": "Second value to be compared with",
                "show": {
                  "conditions[$index].type": "boolean"
                }
              }
            ],
            "id": "conditionAgentflow_0-input-conditions-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "conditions": [
            {
              "type": "string",
              "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.next\" data-label=\"$flow.state.next\">{{ $flow.state.next }}</span> </p>",
              "operation": "equal",
              "value2": "<p>SOFTWARE</p>"
            },
            {
              "type": "string",
              "value1": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.next\" data-label=\"$flow.state.next\">{{ $flow.state.next }}</span> </p>",
              "operation": "equal",
              "value2": "<p>REVIEWER</p>"
            }
          ]
        },
        "outputAnchors": [
          {
            "id": "conditionAgentflow_0-output-0",
            "label": 0,
            "name": 0,
            "description": "Condition 0"
          },
          {
            "id": "conditionAgentflow_0-output-1",
            "label": 1,
            "name": 1,
            "description": "Condition 1"
          },
          {
            "id": "conditionAgentflow_0-output-2",
            "label": 2,
            "name": 2,
            "description": "Else"
          }
        ],
        "outputs": {
          "conditionAgentflow": ""
        },
        "selected": false
      },
      "type": "agentFlow",
      "width": 147,
      "height": 100,
      "positionAbsolute": {
        "x": 632.6376351781316,
        "y": 44.06337565982208
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "llmAgentflow_1",
      "position": {
        "x": 874.4752250712392,
        "y": -110.49146731274378
      },
      "data": {
        "id": "llmAgentflow_1",
        "label": "Software Engineer",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_1-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_1-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_1-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_1-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_1-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_1-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_1-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_1-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_1-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_1-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAICustom",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>You are a full stack web developer.</p><p>Follow the instructions provided by the supervisor node.</p>"
            }
          ],
          "llmEnableMemory": true,
          "llmMemoryType": "allMessages",
          "llmUserMessage": "<p>Supervisor instructions:</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.instructions\" data-label=\"$flow.state.instructions\">{{ $flow.state.instructions }}</span> </p>",
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": "",
          "llmModelConfig": {
            "cache": "",
            "modelName": "your-model-id",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "your-model-endpoint",
            "baseOptions": "",
            "llmModel": "chatOpenAICustom"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_1-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 293,
      "height": 72,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 874.4752250712392,
        "y": -110.49146731274378
      }
    },
    {
      "id": "loopAgentflow_0",
      "position": {
        "x": 1140.2828506850096,
        "y": -241.9892448204126
      },
      "data": {
        "id": "loopAgentflow_0",
        "label": "Loop to Supervisor",
        "version": 1,
        "name": "loopAgentflow",
        "type": "Loop",
        "color": "#FFA07A",
        "hideOutput": true,
        "baseClasses": [
          "Loop"
        ],
        "category": "Agent Flows",
        "description": "Loop back to a previous node",
        "inputParams": [
          {
            "label": "Loop Back To",
            "name": "loopBackToNode",
            "type": "asyncOptions",
            "loadMethod": "listPreviousNodes",
            "freeSolo": true,
            "id": "loopAgentflow_0-input-loopBackToNode-asyncOptions",
            "display": true
          },
          {
            "label": "Max Loop Count",
            "name": "maxLoopCount",
            "type": "number",
            "default": 5,
            "id": "loopAgentflow_0-input-maxLoopCount-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "loopBackToNode": "llmAgentflow_0-Supervisor",
          "maxLoopCount": "10"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 195,
      "height": 66,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1140.2828506850096,
        "y": -241.9892448204126
      }
    },
    {
      "id": "llmAgentflow_2",
      "position": {
        "x": 872.3399689285774,
        "y": 50.198281169132585
      },
      "data": {
        "id": "llmAgentflow_2",
        "label": "Software Reviewer",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_2-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_2-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_2-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_2-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_2-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_2-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_2-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_2-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_2-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_2-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAICustom",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>As a Quality Assurance Engineer, you are an integral part of our development team, ensuring that our software products are of the highest quality. Your meticulous attention to detail and expertise in testing methodologies are crucial in identifying defects and ensuring that our code meets the highest standards.</p><p>Your goal is to ensure the delivery of high-quality software through thorough code review and testing.</p><p>Review the codebase for the new feature designed and implemented by the Senior Software Engineer. Your expertise goes beyond mere code inspection; you are adept at ensuring that developments not only function as intended but also adhere to the team's coding standards, enhance maintainability, and seamlessly integrate with existing systems.</p><p>With a deep appreciation for collaborative development, you provide constructive feedback, guiding contributors towards best practices and fostering a culture of continuous improvement. Your meticulous approach to reviewing code, coupled with your ability to foresee potential issues and recommend proactive solutions, ensures the delivery of high-quality software that is robust, scalable, and aligned with the team's strategic goals.</p><p>Always pass back the review and feedback to Senior Software Engineer.</p>"
            }
          ],
          "llmEnableMemory": true,
          "llmMemoryType": "allMessages",
          "llmUserMessage": "<p>Supervisor instructions:</p><p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.instructions\" data-label=\"$flow.state.instructions\">{{ $flow.state.instructions }}</span> </p>",
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": "",
          "llmModelConfig": {
            "cache": "",
            "modelName": "your-model-id",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "your-model-endpoint",
            "baseOptions": "",
            "llmModel": "chatOpenAICustom"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_2-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 293,
      "height": 72,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 872.3399689285774,
        "y": 50.198281169132585
      }
    },
    {
      "id": "loopAgentflow_3",
      "position": {
        "x": 1240.5799084758846,
        "y": 40.42263081949608
      },
      "data": {
        "id": "loopAgentflow_3",
        "label": "Loop to Supervisor",
        "version": 1,
        "name": "loopAgentflow",
        "type": "Loop",
        "color": "#FFA07A",
        "hideOutput": true,
        "baseClasses": [
          "Loop"
        ],
        "category": "Agent Flows",
        "description": "Loop back to a previous node",
        "inputParams": [
          {
            "label": "Loop Back To",
            "name": "loopBackToNode",
            "type": "asyncOptions",
            "loadMethod": "listPreviousNodes",
            "freeSolo": true,
            "id": "loopAgentflow_3-input-loopBackToNode-asyncOptions",
            "display": true
          },
          {
            "label": "Max Loop Count",
            "name": "maxLoopCount",
            "type": "number",
            "default": 5,
            "id": "loopAgentflow_3-input-maxLoopCount-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "loopBackToNode": "llmAgentflow_0-Supervisor",
          "maxLoopCount": "10"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 195,
      "height": 66,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1240.5799084758846,
        "y": 40.42263081949608
      }
    },
    {
      "id": "llmAgentflow_3",
      "position": {
        "x": 882.2598467634614,
        "y": 238.1730646364603
      },
      "data": {
        "id": "llmAgentflow_3",
        "label": "Generate Final Response",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_3-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_3-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_3-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_3-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_3-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_3-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_3-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_3-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_3-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_3-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenAICustom",
          "llmMessages": [],
          "llmEnableMemory": true,
          "llmMemoryType": "allMessages",
          "llmUserMessage": "<p>Given the above conversations, generate a detailed solution developed by the Software Engineer and code reviewer.</p><p>Include full code, improvement and reviews.</p>",
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": "",
          "llmModelConfig": {
            "cache": "",
            "modelName": "your-model-id",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "your-model-endpoint",
            "baseOptions": "",
            "llmModel": "chatOpenAICustom"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_3-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 293,
      "height": 72,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 882.2598467634614,
        "y": 238.1730646364603
      }
    }
  ],
  "edges": [
    {
      "source": "startAgentflow_0",
      "sourceHandle": "startAgentflow_0-output-startAgentflow",
      "target": "llmAgentflow_0",
      "targetHandle": "llmAgentflow_0",
      "data": {
        "sourceColor": "#7EE787",
        "targetColor": "#64B5F6",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "startAgentflow_0-startAgentflow_0-output-startAgentflow-llmAgentflow_0-llmAgentflow_0"
    },
    {
      "source": "llmAgentflow_0",
      "sourceHandle": "llmAgentflow_0-output-llmAgentflow",
      "target": "conditionAgentflow_0",
      "targetHandle": "conditionAgentflow_0",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#FFB938",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_0-llmAgentflow_0-output-llmAgentflow-conditionAgentflow_0-conditionAgentflow_0"
    },
    {
      "source": "conditionAgentflow_0",
      "sourceHandle": "conditionAgentflow_0-output-0",
      "target": "llmAgentflow_1",
      "targetHandle": "llmAgentflow_1",
      "data": {
        "sourceColor": "#FFB938",
        "targetColor": "#64B5F6",
        "edgeLabel": "0",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentflow_0-conditionAgentflow_0-output-0-llmAgentflow_1-llmAgentflow_1"
    },
    {
      "source": "llmAgentflow_1",
      "sourceHandle": "llmAgentflow_1-output-llmAgentflow",
      "target": "loopAgentflow_0",
      "targetHandle": "loopAgentflow_0",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#FFA07A",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_1-llmAgentflow_1-output-llmAgentflow-loopAgentflow_0-loopAgentflow_0"
    },
    {
      "source": "llmAgentflow_2",
      "sourceHandle": "llmAgentflow_2-output-llmAgentflow",
      "target": "loopAgentflow_3",
      "targetHandle": "loopAgentflow_3",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#FFA07A",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_2-llmAgentflow_2-output-llmAgentflow-loopAgentflow_3-loopAgentflow_3"
    },
    {
      "source": "conditionAgentflow_0",
      "sourceHandle": "conditionAgentflow_0-output-1",
      "target": "llmAgentflow_2",
      "targetHandle": "llmAgentflow_2",
      "data": {
        "sourceColor": "#FFB938",
        "targetColor": "#64B5F6",
        "edgeLabel": "1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentflow_0-conditionAgentflow_0-output-1-llmAgentflow_2-llmAgentflow_2"
    },
    {
      "source": "conditionAgentflow_0",
      "sourceHandle": "conditionAgentflow_0-output-2",
      "target": "llmAgentflow_3",
      "targetHandle": "llmAgentflow_3",
      "data": {
        "sourceColor": "#FFB938",
        "targetColor": "#64B5F6",
        "edgeLabel": "2",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentflow_0-conditionAgentflow_0-output-2-llmAgentflow_3-llmAgentflow_3"
    }
  ]
}